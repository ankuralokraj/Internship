{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9b3ee9",
   "metadata": {},
   "source": [
    "# Q1) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84563dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb4bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  home url of wikipedia is \"https://en.wikipedia.org/wiki/Main_Page\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1938a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url=\"https://en.wikipedia.org/wiki/Main_Page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0dba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://en.wikipedia.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fef1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "page= requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d8fca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09faf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420288e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1>,\n",
       " <h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header= soup.find_all([\"h1\",\"h2\"])\n",
    "header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458500dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page',\n",
       " 'Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header=[]\n",
    "for i in soup.find_all([\"h1\",\"h2\"]):\n",
    "    header.append(i.text)\n",
    "    \n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1250c477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d66431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Header\n",
       "0                      Main Page\n",
       "1           Welcome to Wikipedia\n",
       "2  From today's featured article\n",
       "3               Did you know ...\n",
       "4                    In the news\n",
       "5                    On this day\n",
       "6       Today's featured picture\n",
       "7       Other areas of Wikipedia\n",
       "8    Wikipedia's sister projects\n",
       "9            Wikipedia languages"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Header\":header})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb8e8f",
   "metadata": {},
   "source": [
    "# Q2) Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027b1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d74b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd8a4713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eabc9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7625cd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Shawshank Redemption',\n",
       " 'The Godfather',\n",
       " 'The Dark Knight',\n",
       " 'The Godfather Part II',\n",
       " '12 Angry Men',\n",
       " \"Schindler's List\",\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'Pulp Fiction',\n",
       " 'The Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " 'Forrest Gump',\n",
       " 'Fight Club',\n",
       " 'The Lord of the Rings: The Two Towers',\n",
       " 'Inception',\n",
       " 'The Empire Strikes Back',\n",
       " 'The Matrix',\n",
       " 'GoodFellas',\n",
       " \"One Flew Over the Cuckoo's Nest\",\n",
       " 'Se7en',\n",
       " \"It's a Wonderful Life\",\n",
       " 'Shichinin no samurai',\n",
       " 'The Silence of the Lambs',\n",
       " 'Saving Private Ryan',\n",
       " 'Cidade de Deus',\n",
       " 'Interstellar',\n",
       " 'La vita è bella',\n",
       " 'The Green Mile',\n",
       " 'Star Wars',\n",
       " 'Terminator 2: Judgment Day',\n",
       " 'Back to the Future',\n",
       " 'Sen to Chihiro no kamikakushi',\n",
       " 'The Pianist',\n",
       " 'Psycho',\n",
       " 'Gisaengchung',\n",
       " 'Léon',\n",
       " 'The Lion King',\n",
       " 'Gladiator',\n",
       " 'American History X',\n",
       " 'The Departed',\n",
       " 'Whiplash',\n",
       " 'The Prestige',\n",
       " 'The Usual Suspects',\n",
       " 'Casablanca',\n",
       " 'Hotaru no haka',\n",
       " 'Seppuku',\n",
       " 'The Intouchables',\n",
       " 'Modern Times',\n",
       " 'Once Upon a Time in the West',\n",
       " 'Nuovo Cinema Paradiso',\n",
       " 'Rear Window']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies_name=[]\n",
    "for i in soup.find_all(\"td\",class_=\"titleColumn\"):\n",
    "    name=i.find(\"a\").text\n",
    "    top_movies_name.append(name)\n",
    "    \n",
    "top_50_movies_name=top_movies_name[0:50]\n",
    "top_50_movies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e73b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(2008)',\n",
       " '(1974)',\n",
       " '(1957)',\n",
       " '(1993)',\n",
       " '(2003)',\n",
       " '(1994)',\n",
       " '(2001)',\n",
       " '(1966)',\n",
       " '(1994)',\n",
       " '(1999)',\n",
       " '(2002)',\n",
       " '(2010)',\n",
       " '(1980)',\n",
       " '(1999)',\n",
       " '(1990)',\n",
       " '(1975)',\n",
       " '(1995)',\n",
       " '(1946)',\n",
       " '(1954)',\n",
       " '(1991)',\n",
       " '(1998)',\n",
       " '(2002)',\n",
       " '(2014)',\n",
       " '(1997)',\n",
       " '(1999)',\n",
       " '(1977)',\n",
       " '(1991)',\n",
       " '(1985)',\n",
       " '(2001)',\n",
       " '(2002)',\n",
       " '(1960)',\n",
       " '(2019)',\n",
       " '(1994)',\n",
       " '(1994)',\n",
       " '(2000)',\n",
       " '(1998)',\n",
       " '(2006)',\n",
       " '(2014)',\n",
       " '(2006)',\n",
       " '(1995)',\n",
       " '(1942)',\n",
       " '(1988)',\n",
       " '(1962)',\n",
       " '(2011)',\n",
       " '(1936)',\n",
       " '(1968)',\n",
       " '(1988)',\n",
       " '(1954)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies_year=[]\n",
    "for i in soup.find_all(\"span\",class_=\"secondaryInfo\"):\n",
    "    top_movies_year.append(i.text)\n",
    "    \n",
    "top_50_movies_year =top_movies_year[0:50]\n",
    "top_50_movies_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d000c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9.2',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '9.0',\n",
       " '8.9',\n",
       " '8.9',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies_rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"ratingColumn imdbRating\"):\n",
    "#     name=i.find(\"a\").text\n",
    "#     top_movies.append(name)\n",
    "    top_movies_rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "top_50_movies_rating=top_movies_rating[0:50]\n",
    "top_50_movies_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec47dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame({\"Name\":top_50_movies_name,\"Rating\":top_50_movies_rating,\"Year of release\":top_50_movies_year,\"Rating\":top_50_movies_rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6f90de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>8.7</td>\n",
       "      <td>(1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>American History X</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1936)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name Rating Year of release\n",
       "0                            The Shawshank Redemption    9.2          (1994)\n",
       "1                                       The Godfather    9.2          (1972)\n",
       "2                                     The Dark Knight    9.0          (2008)\n",
       "3                               The Godfather Part II    9.0          (1974)\n",
       "4                                        12 Angry Men    9.0          (1957)\n",
       "5                                    Schindler's List    8.9          (1993)\n",
       "6       The Lord of the Rings: The Return of the King    8.9          (2003)\n",
       "7                                        Pulp Fiction    8.8          (1994)\n",
       "8   The Lord of the Rings: The Fellowship of the Ring    8.8          (2001)\n",
       "9                     Il buono, il brutto, il cattivo    8.8          (1966)\n",
       "10                                       Forrest Gump    8.8          (1994)\n",
       "11                                         Fight Club    8.7          (1999)\n",
       "12              The Lord of the Rings: The Two Towers    8.7          (2002)\n",
       "13                                          Inception    8.7          (2010)\n",
       "14                            The Empire Strikes Back    8.7          (1980)\n",
       "15                                         The Matrix    8.7          (1999)\n",
       "16                                         GoodFellas    8.7          (1990)\n",
       "17                    One Flew Over the Cuckoo's Nest    8.6          (1975)\n",
       "18                                              Se7en    8.6          (1995)\n",
       "19                              It's a Wonderful Life    8.6          (1946)\n",
       "20                               Shichinin no samurai    8.6          (1954)\n",
       "21                           The Silence of the Lambs    8.6          (1991)\n",
       "22                                Saving Private Ryan    8.6          (1998)\n",
       "23                                     Cidade de Deus    8.6          (2002)\n",
       "24                                       Interstellar    8.6          (2014)\n",
       "25                                    La vita è bella    8.6          (1997)\n",
       "26                                     The Green Mile    8.6          (1999)\n",
       "27                                          Star Wars    8.5          (1977)\n",
       "28                         Terminator 2: Judgment Day    8.5          (1991)\n",
       "29                                 Back to the Future    8.5          (1985)\n",
       "30                      Sen to Chihiro no kamikakushi    8.5          (2001)\n",
       "31                                        The Pianist    8.5          (2002)\n",
       "32                                             Psycho    8.5          (1960)\n",
       "33                                       Gisaengchung    8.5          (2019)\n",
       "34                                               Léon    8.5          (1994)\n",
       "35                                      The Lion King    8.5          (1994)\n",
       "36                                          Gladiator    8.5          (2000)\n",
       "37                                 American History X    8.5          (1998)\n",
       "38                                       The Departed    8.5          (2006)\n",
       "39                                           Whiplash    8.5          (2014)\n",
       "40                                       The Prestige    8.5          (2006)\n",
       "41                                 The Usual Suspects    8.5          (1995)\n",
       "42                                         Casablanca    8.5          (1942)\n",
       "43                                     Hotaru no haka    8.5          (1988)\n",
       "44                                            Seppuku    8.5          (1962)\n",
       "45                                   The Intouchables    8.5          (2011)\n",
       "46                                       Modern Times    8.4          (1936)\n",
       "47                       Once Upon a Time in the West    8.4          (1968)\n",
       "48                              Nuovo Cinema Paradiso    8.4          (1988)\n",
       "49                                        Rear Window    8.4          (1954)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b858844",
   "metadata": {},
   "source": [
    "# Q3) Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year ofrelease) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475d539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f29959de",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=X0V9K80DTN7QEJ45S0WV&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_hd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bdbb28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "28adc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e967d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ramayana: The Legend of Prince Rama',\n",
       " 'Rocketry: The Nambi Effect',\n",
       " 'Nayakan',\n",
       " 'Gol Maal',\n",
       " '777 Charlie',\n",
       " 'Pariyerum Perumal',\n",
       " 'Anbe Sivam',\n",
       " 'Apur Sansar',\n",
       " '3 Idiots',\n",
       " 'Manichitrathazhu',\n",
       " 'Jai Bhim',\n",
       " '#Home',\n",
       " 'Soorarai Pottru',\n",
       " 'Black Friday',\n",
       " 'Kumbalangi Nights',\n",
       " 'C/o Kancharapalem',\n",
       " 'Taare Zameen Par',\n",
       " 'Kireedam',\n",
       " 'Dangal',\n",
       " 'Kaithi',\n",
       " 'Jersey',\n",
       " '96',\n",
       " 'Maya Bazaar',\n",
       " 'Natsamrat',\n",
       " 'Asuran',\n",
       " 'Drishyam 2',\n",
       " 'Thevar Magan',\n",
       " 'Sita Ramam',\n",
       " 'Visaaranai',\n",
       " 'Sarpatta Parambarai',\n",
       " 'Thalapathi',\n",
       " 'Nadodikkattu',\n",
       " 'Pather Panchali',\n",
       " 'Drishyam',\n",
       " 'Thani Oruvan',\n",
       " 'Jaane Bhi Do Yaaro',\n",
       " 'Vada Chennai',\n",
       " 'Aparajito',\n",
       " 'Khosla Ka Ghosla!',\n",
       " 'Sardar Udham',\n",
       " 'Anniyan',\n",
       " 'Ratsasan',\n",
       " 'Chupke Chupke',\n",
       " 'Gangs of Wasseypur',\n",
       " 'Drishyam',\n",
       " 'Mahanati',\n",
       " 'Peranbu',\n",
       " 'Bangalore Days',\n",
       " 'Premam',\n",
       " 'Satya']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ind_movies_name=[]\n",
    "for i in soup.find_all(\"td\",class_=\"titleColumn\"):\n",
    "    name=i.find(\"a\").text\n",
    "    top_ind_movies_name.append(name)\n",
    "    \n",
    "top_ind_50_movies_name=top_ind_movies_name[0:50]\n",
    "top_ind_50_movies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5534437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1993)',\n",
       " '(2022)',\n",
       " '(1987)',\n",
       " '(1979)',\n",
       " '(2022)',\n",
       " '(2018)',\n",
       " '(2003)',\n",
       " '(1959)',\n",
       " '(2009)',\n",
       " '(1993)',\n",
       " '(2021)',\n",
       " '(2021)',\n",
       " '(2020)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2007)',\n",
       " '(1989)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(1957)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2021)',\n",
       " '(1992)',\n",
       " '(2022)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(1991)',\n",
       " '(1987)',\n",
       " '(1955)',\n",
       " '(2013)',\n",
       " '(2015)',\n",
       " '(1983)',\n",
       " '(2018)',\n",
       " '(1956)',\n",
       " '(2006)',\n",
       " '(2021)',\n",
       " '(2005)',\n",
       " '(2018)',\n",
       " '(1975)',\n",
       " '(2012)',\n",
       " '(2015)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(2014)',\n",
       " '(2015)',\n",
       " '(1998)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ind_movies_year=[]\n",
    "for i in soup.find_all(\"span\",class_=\"secondaryInfo\"):\n",
    "    top_ind_movies_year.append(i.text)\n",
    "    \n",
    "top_ind_50_movies_year =top_ind_movies_year[0:50]\n",
    "top_ind_50_movies_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68a6a604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.6',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ind_movies_rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"ratingColumn imdbRating\"):\n",
    "    top_ind_movies_rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "top_ind_50_movies_rating=top_ind_movies_rating[0:50]\n",
    "top_ind_50_movies_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f128f716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>777 Charlie</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#Home</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kumbalangi Nights</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kaithi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maya Bazaar</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Natsamrat</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Asuran</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thevar Magan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sita Ramam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Visaaranai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sarpatta Parambarai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thalapathi</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nadodikkattu</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Jaane Bhi Do Yaaro</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vada Chennai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Aparajito</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sardar Udham</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ratsasan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Chupke Chupke</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mahanati</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Peranbu</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Premam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Satya</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name Rating Year of release\n",
       "0   Ramayana: The Legend of Prince Rama    8.6          (1993)\n",
       "1            Rocketry: The Nambi Effect    8.4          (2022)\n",
       "2                               Nayakan    8.4          (1987)\n",
       "3                              Gol Maal    8.4          (1979)\n",
       "4                           777 Charlie    8.4          (2022)\n",
       "5                     Pariyerum Perumal    8.4          (2018)\n",
       "6                            Anbe Sivam    8.4          (2003)\n",
       "7                           Apur Sansar    8.4          (1959)\n",
       "8                              3 Idiots    8.4          (2009)\n",
       "9                      Manichitrathazhu    8.3          (1993)\n",
       "10                             Jai Bhim    8.3          (2021)\n",
       "11                                #Home    8.3          (2021)\n",
       "12                      Soorarai Pottru    8.3          (2020)\n",
       "13                         Black Friday    8.3          (2004)\n",
       "14                    Kumbalangi Nights    8.3          (2019)\n",
       "15                    C/o Kancharapalem    8.3          (2018)\n",
       "16                     Taare Zameen Par    8.3          (2007)\n",
       "17                             Kireedam    8.3          (1989)\n",
       "18                               Dangal    8.3          (2016)\n",
       "19                               Kaithi    8.3          (2019)\n",
       "20                               Jersey    8.3          (2019)\n",
       "21                                   96    8.3          (2018)\n",
       "22                          Maya Bazaar    8.2          (1957)\n",
       "23                            Natsamrat    8.2          (2016)\n",
       "24                               Asuran    8.2          (2019)\n",
       "25                           Drishyam 2    8.2          (2021)\n",
       "26                         Thevar Magan    8.2          (1992)\n",
       "27                           Sita Ramam    8.2          (2022)\n",
       "28                           Visaaranai    8.2          (2015)\n",
       "29                  Sarpatta Parambarai    8.2          (2021)\n",
       "30                           Thalapathi    8.2          (1991)\n",
       "31                         Nadodikkattu    8.2          (1987)\n",
       "32                      Pather Panchali    8.2          (1955)\n",
       "33                             Drishyam    8.2          (2013)\n",
       "34                         Thani Oruvan    8.2          (2015)\n",
       "35                   Jaane Bhi Do Yaaro    8.2          (1983)\n",
       "36                         Vada Chennai    8.2          (2018)\n",
       "37                            Aparajito    8.2          (1956)\n",
       "38                    Khosla Ka Ghosla!    8.2          (2006)\n",
       "39                         Sardar Udham    8.2          (2021)\n",
       "40                              Anniyan    8.2          (2005)\n",
       "41                             Ratsasan    8.1          (2018)\n",
       "42                        Chupke Chupke    8.1          (1975)\n",
       "43                   Gangs of Wasseypur    8.1          (2012)\n",
       "44                             Drishyam    8.1          (2015)\n",
       "45                             Mahanati    8.1          (2018)\n",
       "46                              Peranbu    8.1          (2018)\n",
       "47                       Bangalore Days    8.1          (2014)\n",
       "48                               Premam    8.1          (2015)\n",
       "49                                Satya    8.1          (1998)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_df= pd.DataFrame({\"Name\":top_ind_50_movies_name,\"Rating\":top_ind_50_movies_rating,\"Year of release\":top_ind_50_movies_year})\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6191fd",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b26128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8932b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://presidentofindia.nic.in/former-presidents.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "179e2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f85196",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19caddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Ram Nath Kovind ',\n",
       " 'Shri Pranab Mukherjee ',\n",
       " 'Smt Pratibha Devisingh Patil ',\n",
       " 'DR. A.P.J. Abdul Kalam ',\n",
       " 'Shri K. R. Narayanan ',\n",
       " 'Dr Shankar Dayal Sharma ',\n",
       " 'Shri R Venkataraman ',\n",
       " 'Giani Zail Singh ',\n",
       " 'Shri Neelam Sanjiva Reddy ',\n",
       " 'Dr. Fakhruddin Ali Ahmed ',\n",
       " 'Shri Varahagiri Venkata Giri ',\n",
       " 'Dr. Zakir Husain ',\n",
       " 'Dr. Sarvepalli Radhakrishnan ',\n",
       " 'Dr. Rajendra Prasad ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Former_President_name=[]\n",
    "for i in soup.find_all(\"h3\"):\n",
    "    i=i.text[:i.text.find(\"(\")]\n",
    "    Former_President_name.append(i)\n",
    "    \n",
    "Former_President_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f79adfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 25 July, 2017 to 25 July, 2022 ',\n",
       " ' 25 July, 2012 to 25 July, 2017 ',\n",
       " ' 25 July, 2007 to 25 July, 2012 ',\n",
       " ' 25 July, 2002 to 25 July, 2007 ',\n",
       " ' 25 July, 1997 to 25 July, 2002 ',\n",
       " ' 25 July, 1992 to 25 July, 1997 ',\n",
       " ' 25 July, 1987 to 25 July, 1992 ',\n",
       " ' 25 July, 1982 to 25 July, 1987 ',\n",
       " ' 25 July, 1977 to 25 July, 1982 ',\n",
       " ' 24 August, 1974 to 11 February, 1977',\n",
       " ' 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " ' 13 May, 1967 to 3 May, 1969',\n",
       " ' 13 May, 1962 to 13 May, 1967',\n",
       " ' 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Term_Of_Office= []\n",
    "for i in soup.find_all(\"div\",class_=\"presidentListing\"):\n",
    "        j=i.find(\"p\")\n",
    "        Term_Of_Office.append(j.text.replace(\"Term of Office:\",\"\"))\n",
    "        \n",
    "    \n",
    "    \n",
    "Term_Of_Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be672d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term Of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term Of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents_df= pd.DataFrame({\"Name\":Former_President_name,\"Term Of Office\":Term_Of_Office})\n",
    "presidents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6fb13",
   "metadata": {},
   "source": [
    "# Q5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84f3fa",
   "metadata": {},
   "source": [
    "### a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32517b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "713355ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5c7529b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d4f2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3074de9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'New Zealand',\n",
       " 'India',\n",
       " 'England',\n",
       " 'Pakistan',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'West Indies',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_names=[]\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    team_names.append(i.text)\n",
    "    \n",
    "team_names\n",
    "Top_10_team_names=team_names[:10]\n",
    "Top_10_team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77404368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35', '31', '47', '36', '25', '31', '38', '36', '43', '20']\n",
      "['3,965', '3,504', '5,294', '3,988', '2,649', '3,141', '3,625', '3,099', '3,105', '1,419']\n"
     ]
    }
   ],
   "source": [
    "team_matches=[]\n",
    "for i in soup.find(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    team_matches.append(i.text)\n",
    "for i in soup.find(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    team_matches.append(i.text)\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"):\n",
    "    team_matches.append(i.text)\n",
    "    \n",
    "\n",
    "Top_10_team_matches=team_matches[:20:2]\n",
    "print(Top_10_team_matches)\n",
    "\n",
    "Top_10_team_points=team_matches[1:21:2]\n",
    "print(Top_10_team_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44bfab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['113', '113', '113', '111', '106', '101', '95', '86', '72', '71']\n"
     ]
    }
   ],
   "source": [
    "team_rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    team_rating.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    team_rating.append(i.text)\n",
    "Top_10_team_rating=team_rating[:10]\n",
    "print(Top_10_team_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eea7840a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>35</td>\n",
       "      <td>3,965</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,504</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>47</td>\n",
       "      <td>5,294</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>3,988</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>31</td>\n",
       "      <td>3,141</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>38</td>\n",
       "      <td>3,625</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>36</td>\n",
       "      <td>3,099</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>43</td>\n",
       "      <td>3,105</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Rating\n",
       "0     Australia      35  3,965    113\n",
       "1   New Zealand      31  3,504    113\n",
       "2         India      47  5,294    113\n",
       "3       England      36  3,988    111\n",
       "4      Pakistan      25  2,649    106\n",
       "5  South Africa      31  3,141    101\n",
       "6    Bangladesh      38  3,625     95\n",
       "7     Sri Lanka      36  3,099     86\n",
       "8   West Indies      43  3,105     72\n",
       "9   Afghanistan      20  1,419     71"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_ODI_teams= pd.DataFrame({\"Team\":Top_10_team_names,\"Matches\":Top_10_team_matches,\"Points\":Top_10_team_points,\"Rating\":Top_10_team_rating})\n",
    "Top_10_ODI_teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d3d52",
   "metadata": {},
   "source": [
    "### b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc2eef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab748ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47a797c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "374e4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab9c8f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Rassie van der Dussen',\n",
       " 'Imam-ul-Haq',\n",
       " 'Shubman Gill',\n",
       " 'David Warner',\n",
       " 'Virat Kohli',\n",
       " 'Quinton de Kock',\n",
       " 'Rohit Sharma',\n",
       " 'Steve Smith',\n",
       " 'Fakhar Zaman']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batsmen_names=[]\n",
    "for i in soup.find(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "    Batsmen_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "    Batsmen_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_Batsmen_names=Batsmen_names[:10]\n",
    "Top_10_Batsmen_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31e0b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'SA', 'PAK', 'IND', 'AUS', 'IND', 'SA', 'IND', 'AUS', 'PAK']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_names=[]\n",
    "t_name=[]\n",
    "for i in soup.find(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "      \n",
    "        t_name.append(i.text)\n",
    "        t_name = [t.strip() for t in t_name if t.strip()]\n",
    "team_names.append(t_name[0])\n",
    "        \n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team_names.append(i.text.replace(\"\\n\",\"\").replace(\"'',\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_team_names=team_names[:10]\n",
    "Top_10_team_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4f04781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['887', '777', '740', '738', '726', '719', '718', '707', '702', '699']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_rating=[]\n",
    "t_rating=[]\n",
    "for i in soup.find(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "      \n",
    "        t_rating.append(i.text)\n",
    "        t_rating = [t.strip() for t in t_rating if t.strip()]\n",
    "team_rating.append(t_rating[1])\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    team_rating.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Top_10_team_rating=team_rating[:10]\n",
    "Top_10_team_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9065909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batting_player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Batting_player Team Rating\n",
       "0             Babar Azam  PAK    887\n",
       "1  Rassie van der Dussen   SA    777\n",
       "2            Imam-ul-Haq  PAK    740\n",
       "3           Shubman Gill  IND    738\n",
       "4           David Warner  AUS    726\n",
       "5            Virat Kohli  IND    719\n",
       "6        Quinton de Kock   SA    718\n",
       "7           Rohit Sharma  IND    707\n",
       "8            Steve Smith  AUS    702\n",
       "9           Fakhar Zaman  PAK    699"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_ODI_batting_player= pd.DataFrame({\"Batting_player\":Top_10_Batsmen_names,\"Team\":Top_10_team_names,\"Rating\":Top_10_team_rating})\n",
    "Top_10_ODI_batting_player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34517ede",
   "metadata": {},
   "source": [
    "### c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3662f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c575a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b805388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86e44778",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49d78f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Josh Hazlewood',\n",
       " 'Trent Boult',\n",
       " 'Mohammed Siraj',\n",
       " 'Mitchell Starc',\n",
       " 'Matt Henry',\n",
       " 'Rashid Khan',\n",
       " 'Adam Zampa',\n",
       " 'Shaheen Afridi',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Shakib Al Hasan']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bowler_1_names=[]\n",
    "Bowler_names=[]\n",
    "g=0\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "    \n",
    "    if g==1:\n",
    "        Bowler_1_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "        break\n",
    "    else :\n",
    "        g=g+1\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "    Bowler_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_Bowler_names=Bowler_1_names + Bowler_names[9:18]\n",
    "Top_10_Bowler_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9b64518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'NZ', 'IND', 'AUS', 'NZ', 'AFG', 'AUS', 'PAK', 'AFG', 'BAN']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_names=[]\n",
    "team_1_names=[]\n",
    "t_name=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "      \n",
    "        t_name.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "        t_name = [t.strip() for t in t_name if t.strip()]\n",
    "team_1_names.append(t_name[1][:3])\n",
    "        \n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team_names.append(i.text.replace(\"\\n\",\"\").replace(\"'',\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_team_names=team_1_names+team_names[9:18]\n",
    "Top_10_team_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd48aaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['705', '694', '691', '686', '676', '659', '652', '641', '637', '636']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_rating=[]\n",
    "team_1_rating=[]\n",
    "t_rating=[]\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "\n",
    "        t_rating.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "        t_rating = [t.strip() for t in t_rating if t.strip()]\n",
    "team_1_rating.append(t_rating[1][3:6])\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    team_rating.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Top_10_team_rating=team_1_rating+team_rating[9:18]\n",
    "Top_10_team_rating\n",
    "# team_1_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "207a2fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bowling_player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bowling_player Team Rating\n",
       "0    Josh Hazlewood  AUS    705\n",
       "1       Trent Boult   NZ    694\n",
       "2    Mohammed Siraj  IND    691\n",
       "3    Mitchell Starc  AUS    686\n",
       "4        Matt Henry   NZ    676\n",
       "5       Rashid Khan  AFG    659\n",
       "6        Adam Zampa  AUS    652\n",
       "7    Shaheen Afridi  PAK    641\n",
       "8  Mujeeb Ur Rahman  AFG    637\n",
       "9   Shakib Al Hasan  BAN    636"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_ODI_bowling_player= pd.DataFrame({\"bowling_player\":Top_10_Bowler_names,\"Team\":Top_10_team_names,\"Rating\":Top_10_team_rating})\n",
    "Top_10_ODI_bowling_player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafea91d",
   "metadata": {},
   "source": [
    "# Q6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data framea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a65bb",
   "metadata": {},
   "source": [
    "### a)Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3138c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38b4957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b957316",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "405ef55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a77ac8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Thailand',\n",
       " 'Pakistan',\n",
       " 'Sri Lanka']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_names=[]\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    team_names.append(i.text)\n",
    "    \n",
    "team_names\n",
    "Top_10_team_names=team_names[:10]\n",
    "Top_10_team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cb03602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21', '28', '26', '27', '25', '27', '13', '11', '27', '8']\n",
      "['3,603', '3,342', '3,098', '2,820', '2,553', '2,535', '983', '821', '1,678', '353']\n"
     ]
    }
   ],
   "source": [
    "team_matches=[]\n",
    "for i in soup.find(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    team_matches.append(i.text)\n",
    "for i in soup.find(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    team_matches.append(i.text)\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"):\n",
    "    team_matches.append(i.text)\n",
    "    \n",
    "\n",
    "Top_10_team_matches=team_matches[:20:2]\n",
    "print(Top_10_team_matches)\n",
    "\n",
    "Top_10_team_points=team_matches[1:21:2]\n",
    "print(Top_10_team_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "307e3ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['172', '119', '119', '104', '102', '94', '76', '75', '62', '44']\n"
     ]
    }
   ],
   "source": [
    "team_rating=[]\n",
    "for i in soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    team_rating.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    team_rating.append(i.text)\n",
    "Top_10_team_rating=team_rating[:10]\n",
    "print(Top_10_team_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "532803c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>11</td>\n",
       "      <td>821</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Rating\n",
       "0     Australia      21  3,603    172\n",
       "1       England      28  3,342    119\n",
       "2  South Africa      26  3,098    119\n",
       "3         India      27  2,820    104\n",
       "4   New Zealand      25  2,553    102\n",
       "5   West Indies      27  2,535     94\n",
       "6    Bangladesh      13    983     76\n",
       "7      Thailand      11    821     75\n",
       "8      Pakistan      27  1,678     62\n",
       "9     Sri Lanka       8    353     44"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_women_ODI_teams= pd.DataFrame({\"Team\":Top_10_team_names,\"Matches\":Top_10_team_matches,\"Points\":Top_10_team_points,\"Rating\":Top_10_team_rating})\n",
    "Top_10_women_ODI_teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26522da",
   "metadata": {},
   "source": [
    "### b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31493681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58f9393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76b779f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ad11d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a49c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alyssa Healy',\n",
       " 'Beth Mooney',\n",
       " 'Laura Wolvaardt',\n",
       " 'Natalie Sciver',\n",
       " 'Meg Lanning',\n",
       " 'Harmanpreet Kaur',\n",
       " 'Smriti Mandhana',\n",
       " 'Chamari Athapaththu',\n",
       " 'Amy Satterthwaite',\n",
       " 'Ellyse Perry']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batsmen_names=[]\n",
    "for i in soup.find(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "    Batsmen_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "    Batsmen_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_Batsmen_names=Batsmen_names[:10]\n",
    "Top_10_Batsmen_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0261f0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'AUS', 'SA', 'ENG', 'AUS', 'IND', 'IND', 'SL', 'NZ', 'AUS']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_names=[]\n",
    "t_name=[]\n",
    "for i in soup.find(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "      \n",
    "        t_name.append(i.text)\n",
    "        t_name = [t.strip() for t in t_name if t.strip()]\n",
    "team_names.append(t_name[0])\n",
    "        \n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team_names.append(i.text.replace(\"\\n\",\"\").replace(\"'',\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_team_names=team_names[:10]\n",
    "Top_10_team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1d6658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['762', '754', '732', '731', '717', '716', '714', '655', '641', '626']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_rating=[]\n",
    "t_rating=[]\n",
    "for i in soup.find(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "      \n",
    "        t_rating.append(i.text)\n",
    "        t_rating = [t.strip() for t in t_rating if t.strip()]\n",
    "team_rating.append(t_rating[1])\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    team_rating.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Top_10_team_rating=team_rating[:10]\n",
    "Top_10_team_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5d1807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batting_player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Batting_player Team Rating\n",
       "0         Alyssa Healy  AUS    762\n",
       "1          Beth Mooney  AUS    754\n",
       "2      Laura Wolvaardt   SA    732\n",
       "3       Natalie Sciver  ENG    731\n",
       "4          Meg Lanning  AUS    717\n",
       "5     Harmanpreet Kaur  IND    716\n",
       "6      Smriti Mandhana  IND    714\n",
       "7  Chamari Athapaththu   SL    655\n",
       "8    Amy Satterthwaite   NZ    641\n",
       "9         Ellyse Perry  AUS    626"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_women_ODI_batting_player= pd.DataFrame({\"Batting_player\":Top_10_Batsmen_names,\"Team\":Top_10_team_names,\"Rating\":Top_10_team_rating})\n",
    "Top_10_women_ODI_batting_player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d305bd",
   "metadata": {},
   "source": [
    "### c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "deb550b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d1b1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05c94b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page =requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54d7782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d678ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hayley Matthews',\n",
       " 'Natalie Sciver',\n",
       " 'Ellyse Perry',\n",
       " 'Marizanne Kapp',\n",
       " 'Amelia Kerr',\n",
       " 'Deepti Sharma',\n",
       " 'Ashleigh Gardner',\n",
       " 'Jess Jonassen',\n",
       " 'Nida Dar',\n",
       " 'Sophie Ecclestone']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bowler_1_names=[]\n",
    "Bowler_names=[]\n",
    "g=0\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name\"):\n",
    "    \n",
    "    if g==2:\n",
    "        Bowler_1_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "        break\n",
    "    else :\n",
    "        g=g+1\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "    Bowler_names.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_Bowler_names=Bowler_1_names + Bowler_names[18:27]\n",
    "Top_10_Bowler_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca738f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WI3', 'ENG', 'AUS', 'SA', 'NZ', 'IND', 'AUS', 'AUS', 'PAK', 'ENG']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_names=[]\n",
    "team_1_names=[]\n",
    "t_name=[]\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "      \n",
    "        t_name.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "        t_name = [t.strip() for t in t_name if t.strip()]\n",
    "team_1_names.append(t_name[2][:3])\n",
    "        \n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team_names.append(i.text.replace(\"\\n\",\"\").replace(\"'',\",\"\"))\n",
    "    \n",
    "\n",
    "Top_10_team_names=team_1_names+team_names[18:27]\n",
    "Top_10_team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38c24267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['373', '371', '366', '349', '336', '322', '292', '250', '232', '205']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_rating=[]\n",
    "team_1_rating=[]\n",
    "t_rating=[]\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "\n",
    "        t_rating.append(i.text.replace(\"\\n\",\"\").replace(\" \",\"\"))\n",
    "        t_rating = [t.strip() for t in t_rating if t.strip()]\n",
    "team_1_rating.append(t_rating[2][2:6])\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    team_rating.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Top_10_team_rating=team_1_rating+team_rating[18:27]\n",
    "Top_10_team_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa58419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bowling_player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI3</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bowling_player Team Rating\n",
       "0    Hayley Matthews  WI3    373\n",
       "1     Natalie Sciver  ENG    371\n",
       "2       Ellyse Perry  AUS    366\n",
       "3     Marizanne Kapp   SA    349\n",
       "4        Amelia Kerr   NZ    336\n",
       "5      Deepti Sharma  IND    322\n",
       "6   Ashleigh Gardner  AUS    292\n",
       "7      Jess Jonassen  AUS    250\n",
       "8           Nida Dar  PAK    232\n",
       "9  Sophie Ecclestone  ENG    205"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_women_ODI_bowling_player= pd.DataFrame({\"bowling_player\":Top_10_Bowler_names,\"Team\":Top_10_team_names,\"Rating\":Top_10_team_rating})\n",
    "Top_10_women_ODI_bowling_player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab84c7",
   "metadata": {},
   "source": [
    "# Q7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80e5bf",
   "metadata": {},
   "source": [
    "i)Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "085bca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fee70639",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.cnbc.com/world/?region=world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa909924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "101fd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fea88496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big banks including JPMorgan Chase, PNC asked for final bids on First Republic',\n",
       " 'How to raise a kids with a ‘secure’ attachment style',\n",
       " 'The business case for green sports stadiums and arenas is growing',\n",
       " 'A solid start to earnings season will be put to the test in the week ahead',\n",
       " \"TikTokers are using beef tallow to treat acne: 'It can be hit or miss'\",\n",
       " 'This 28-year-old pays $62 a month to live in a dumpster he built for $5,000—take a look inside',\n",
       " \"As part of the  ‘cocktail culture,' consumers are splurging on dinner and drinks\",\n",
       " \"Why GM is killing the Chevy Bolt — America's cheapest EV — amid record sales\",\n",
       " \"Just a few stocks are behind the market's resilience. A real concern?\",\n",
       " \"Google Cloud's Kurian on road to profit: 'We were not in a very good situation'\",\n",
       " 'Olipop nears $200 million in annual sales—and CEO says Coke, Pepsi have come knocking ',\n",
       " 'This 25-year-old makes $200/hour without a bachelor’s degree',\n",
       " 'The most overbought and oversold S&P 500 stocks include several tech names',\n",
       " \"Mark Cuban says paying Twitter for a blue check hasn't fixed his drop in followers\",\n",
       " 'Goldman Sachs says these are its top picks coming out of earnings.',\n",
       " 'What’s next for SpaceX’s Starship after a dramatic first launch',\n",
       " 'Jim Cramer: Consumer goods stocks are set to keep running, so buy now',\n",
       " \"Amazon drops on slowing cloud growth. Here's how the pros are playing it\",\n",
       " 'Why bitcoin keeps wavering between a store of value and a risk asset',\n",
       " 'California bans the sale of new diesel trucks by 2036']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_headline=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    news_headline.append(i.text)\n",
    "    \n",
    "news_headline=news_headline[0:20]\n",
    "news_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc19c72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 Min Ago',\n",
       " '2 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '6 Hours Ago',\n",
       " '18 Hours Ago',\n",
       " '21 Hours Ago',\n",
       " '21 Hours Ago',\n",
       " '22 Hours Ago']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_time=[]\n",
    "for i in soup.find_all(\"time\",class_=\"LatestNews-timestamp\"):\n",
    "    news_time.append(i.text)\n",
    "    \n",
    "news_time=news_time[:20]\n",
    "news_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7efa0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2023/04/29/first-republic-frc-jpmorgan-chase-bank-of-america-asked-for-bids.html',\n",
       " 'https://www.cnbc.com/2023/04/29/how-to-raise-a-kids-who-will-have-a-secure-attachment-style.html',\n",
       " 'https://www.cnbc.com/2023/04/29/the-business-case-for-green-sports-stadiums-and-arenas-is-growing.html',\n",
       " 'https://www.cnbc.com/2023/04/29/decent-start-to-earnings-season-will-be-put-to-the-test-in-week-ahead.html',\n",
       " 'https://www.cnbc.com/2023/04/29/tiktokers-are-using-beef-tallow-to-treat-acne-heres-what-experts-think.html',\n",
       " 'https://www.cnbc.com/2023/04/29/28-year-old-pays-62-a-month-to-live-in-a-dumpster-he-built-for-5000-in-london-take-a-look-inside.html',\n",
       " 'https://www.cnbc.com/2023/04/29/cocktail-culture-consumers-are-still-splurging-on-dinner-and-drinks.html',\n",
       " 'https://www.cnbc.com/2023/04/29/why-gm-is-killing-the-chevy-bolt-ev-amid-record-sales.html',\n",
       " 'https://www.cnbc.com/2023/04/29/just-a-few-stocks-are-behind-the-markets-recent-resilience-a-real-concern-or-routine-rotation.html',\n",
       " 'https://www.cnbc.com/2023/04/29/google-cloud-boss-thomas-kurians-rocky-path-to-profit.html',\n",
       " 'https://www.cnbc.com/2023/04/29/olipop-nears-200-million-in-annual-sales-coke-pepsi-come-knocking-ceo-says.html',\n",
       " 'https://www.cnbc.com/2023/04/29/25-year-old-notary-signing-agent-makes-200-an-hour-without-bachelors-degree.html',\n",
       " 'https://www.cnbc.com/2023/04/29/herea-re-the-most-overbought-and-oversold-sp-500-stocks-.html',\n",
       " 'https://www.cnbc.com/2023/04/29/mark-cuban-paying-for-twitter-blue-didnt-stop-me-from-losing-followers.html',\n",
       " 'https://www.cnbc.com/2023/04/29/goldman-sachs-says-these-compelling-stocks-are-earnings-season-winners.html',\n",
       " 'https://www.cnbc.com/2023/04/29/spacex-starship-whats-next.html',\n",
       " 'https://www.cnbc.com/2023/04/28/jim-cramer-consumer-goods-stocks-are-set-to-keep-running-and-its-not-too-late-to-buy.html',\n",
       " 'https://www.cnbc.com/2023/04/28/amazon-falls-on-slowing-cloud-growth-how-the-pros-are-playing-it.html',\n",
       " 'https://www.cnbc.com/2023/04/28/why-bitcoin-keeps-wavering-between-a-store-of-value-and-a-risk-asset.html',\n",
       " 'https://www.cnbc.com/2023/04/28/california-bans-the-sale-of-new-diesel-trucks-by-2036.html']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    links.append(i[\"href\"])\n",
    "links=links[0:20]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01b368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c1473cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News_headline</th>\n",
       "      <th>News_time</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big banks including JPMorgan Chase, PNC asked ...</td>\n",
       "      <td>25 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/first-republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to raise a kids with a ‘secure’ attachment...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/how-to-raise-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The business case for green sports stadiums an...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/the-business-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A solid start to earnings season will be put t...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/decent-start-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TikTokers are using beef tallow to treat acne:...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/tiktokers-are-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This 28-year-old pays $62 a month to live in a...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/28-year-old-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As part of the  ‘cocktail culture,' consumers ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/cocktail-cultu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Why GM is killing the Chevy Bolt — America's c...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/why-gm-is-kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Just a few stocks are behind the market's resi...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/just-a-few-sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Google Cloud's Kurian on road to profit: 'We w...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/google-cloud-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Olipop nears $200 million in annual sales—and ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/olipop-nears-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This 25-year-old makes $200/hour without a bac...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/25-year-old-no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The most overbought and oversold S&amp;P 500 stock...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/herea-re-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mark Cuban says paying Twitter for a blue chec...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/mark-cuban-pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Goldman Sachs says these are its top picks com...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/goldman-sachs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What’s next for SpaceX’s Starship after a dram...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/29/spacex-starshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Jim Cramer: Consumer goods stocks are set to k...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/jim-cramer-con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amazon drops on slowing cloud growth. Here's h...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/amazon-falls-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Why bitcoin keeps wavering between a store of ...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/why-bitcoin-ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>California bans the sale of new diesel trucks ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/28/california-ban...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        News_headline     News_time  \\\n",
       "0   Big banks including JPMorgan Chase, PNC asked ...    25 Min Ago   \n",
       "1   How to raise a kids with a ‘secure’ attachment...   2 Hours Ago   \n",
       "2   The business case for green sports stadiums an...   3 Hours Ago   \n",
       "3   A solid start to earnings season will be put t...   3 Hours Ago   \n",
       "4   TikTokers are using beef tallow to treat acne:...   3 Hours Ago   \n",
       "5   This 28-year-old pays $62 a month to live in a...   4 Hours Ago   \n",
       "6   As part of the  ‘cocktail culture,' consumers ...   4 Hours Ago   \n",
       "7   Why GM is killing the Chevy Bolt — America's c...   4 Hours Ago   \n",
       "8   Just a few stocks are behind the market's resi...   5 Hours Ago   \n",
       "9   Google Cloud's Kurian on road to profit: 'We w...   5 Hours Ago   \n",
       "10  Olipop nears $200 million in annual sales—and ...   5 Hours Ago   \n",
       "11  This 25-year-old makes $200/hour without a bac...   5 Hours Ago   \n",
       "12  The most overbought and oversold S&P 500 stock...   5 Hours Ago   \n",
       "13  Mark Cuban says paying Twitter for a blue chec...   5 Hours Ago   \n",
       "14  Goldman Sachs says these are its top picks com...   5 Hours Ago   \n",
       "15  What’s next for SpaceX’s Starship after a dram...   6 Hours Ago   \n",
       "16  Jim Cramer: Consumer goods stocks are set to k...  18 Hours Ago   \n",
       "17  Amazon drops on slowing cloud growth. Here's h...  21 Hours Ago   \n",
       "18  Why bitcoin keeps wavering between a store of ...  21 Hours Ago   \n",
       "19  California bans the sale of new diesel trucks ...  22 Hours Ago   \n",
       "\n",
       "                                                Links  \n",
       "0   https://www.cnbc.com/2023/04/29/first-republic...  \n",
       "1   https://www.cnbc.com/2023/04/29/how-to-raise-a...  \n",
       "2   https://www.cnbc.com/2023/04/29/the-business-c...  \n",
       "3   https://www.cnbc.com/2023/04/29/decent-start-t...  \n",
       "4   https://www.cnbc.com/2023/04/29/tiktokers-are-...  \n",
       "5   https://www.cnbc.com/2023/04/29/28-year-old-pa...  \n",
       "6   https://www.cnbc.com/2023/04/29/cocktail-cultu...  \n",
       "7   https://www.cnbc.com/2023/04/29/why-gm-is-kill...  \n",
       "8   https://www.cnbc.com/2023/04/29/just-a-few-sto...  \n",
       "9   https://www.cnbc.com/2023/04/29/google-cloud-b...  \n",
       "10  https://www.cnbc.com/2023/04/29/olipop-nears-2...  \n",
       "11  https://www.cnbc.com/2023/04/29/25-year-old-no...  \n",
       "12  https://www.cnbc.com/2023/04/29/herea-re-the-m...  \n",
       "13  https://www.cnbc.com/2023/04/29/mark-cuban-pay...  \n",
       "14  https://www.cnbc.com/2023/04/29/goldman-sachs-...  \n",
       "15  https://www.cnbc.com/2023/04/29/spacex-starshi...  \n",
       "16  https://www.cnbc.com/2023/04/28/jim-cramer-con...  \n",
       "17  https://www.cnbc.com/2023/04/28/amazon-falls-o...  \n",
       "18  https://www.cnbc.com/2023/04/28/why-bitcoin-ke...  \n",
       "19  https://www.cnbc.com/2023/04/28/california-ban...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news= pd.DataFrame({\"News_headline\":news_headline,\"News_time\":news_time,\"Links\":links})\n",
    "news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90621b4b",
   "metadata": {},
   "source": [
    "# Q 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd40f5",
   "metadata": {},
   "source": [
    "i)Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80e5fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91735f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8c5c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "111ecb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4ef38e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "for i in soup.find_all(\"h2\",class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    title.append(i.text)\n",
    "    \n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03188ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors=[]\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36c83fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Published_Date=[]\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    Published_Date.append(i.text)\n",
    "    \n",
    "Published_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "764061cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0004370221000862',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000722',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370215000910',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370298000551',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300790',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370218305988',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301855',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370214001386',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370299000521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370219300116',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301533',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370207000793',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300285',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301958',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370297000635',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000515',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000539',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000096',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300868',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000588',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000102',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370213001082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S000437029700043X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000734',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370209001398']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links=[]\n",
    "for i in soup.find_all(\"a\",class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    links.append(i[\"href\"])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9acc2e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI= pd.DataFrame({\"Title\":title,\"Author\":authors,\"Published Date\":Published_Date,\"Paper URL\":links})\n",
    "AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e208dc",
   "metadata": {},
   "source": [
    "# Q9) Write a python program to scrape mentioned details from dineout.co.in and make data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd436d12",
   "metadata": {},
   "source": [
    "i)Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c37d1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b54af42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.dineout.co.in/delhi-restaurants/buffet-special\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1dff9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec08eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a15b1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Restaurant_name=[]\n",
    "for i in soup.find_all(\"a\",class_=\"restnt-name ellipsis\"):\n",
    "    Restaurant_name.append(i.text)\n",
    "    \n",
    "len(Restaurant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aedb4c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Restaurant_Cuisine=[]\n",
    "for i in soup.find_all(\"span\",class_=\"double-line-ellipsis\"):\n",
    "        Restaurant_Cuisine.append(i.text.split(\"|\")[1])\n",
    "    \n",
    "len(Restaurant_Cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94f41680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Restaurant_Location=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-loc ellipsis\"):\n",
    "    \n",
    "    Restaurant_Location.append(i.text)\n",
    "    \n",
    "len(Restaurant_Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2d07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272f414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "306cad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Restaurant_Rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-4\"):\n",
    "   \n",
    "    Restaurant_Rating.append(i.text)\n",
    "    \n",
    "len(Restaurant_Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ed3c4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Restaurant_Image_URL=[]\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "        Restaurant_Image_URL.append(i.get(\"data-src\"))\n",
    "    \n",
    "len(Restaurant_Image_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c064c805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant name                        Cuisine  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "2                        Cafe Knosh           Italian, Continental   \n",
       "3                   Castle Barbeque          Chinese, North Indian   \n",
       "4              The Barbeque Company          North Indian, Chinese   \n",
       "5                       India Grill          North Indian, Italian   \n",
       "6                    Delhi Barbeque                   North Indian   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian   \n",
       "8                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi       4   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida     3.9   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Restaurant=pd.DataFrame({\"Restaurant name\":Restaurant_name,\"Cuisine\":Restaurant_Cuisine,\"Location\":Restaurant_Location,\"Ratings\":Restaurant_Rating,\"Image URL\":Restaurant_Image_URL})\n",
    "Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02785d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61233b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
