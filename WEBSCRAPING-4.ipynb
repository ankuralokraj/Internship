{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b357f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM 1\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5b5804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRISHA ROY\\AppData\\Local\\Temp\\ipykernel_25636\\3270951912.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\TRISHA ROY\\Downloads\\chromedriver_win32.exe\")\n"
     ]
    }
   ],
   "source": [
    "# connecting to webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\TRISHA ROY\\Downloads\\chromedriver_win32.exe\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening Wikipedia webpage\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3167a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list for scraping data\n",
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b3813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank Via X path\n",
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting Name Via X path\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Artist Name Via Xpath\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "    \n",
    "# Extracting Upload date Via Xpath\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA') \n",
    "\n",
    "# Extracting Views via Xpath\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c744e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30, 30, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank),len(Name),len(Artist),len(Views),len(Upload_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de872a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMost Viewed Video on YouTube from Wikipedia :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (in Billons)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.85</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.16</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.70</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>6.20</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.00</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.89</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.30</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.24</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.92</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.89</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.80</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.35</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[34]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.91</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[35]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.87</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.80</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.79</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.66</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[39]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.64</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[40]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.60</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.59</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.52</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.48</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"[44]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.45</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.45</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[46]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.44</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.42</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.41</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[49]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.38</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[50]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.38</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                     \"Axel F\"[34]   \n",
       "14  15.                                      \"Sugar\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[39]   \n",
       "19  20.                          \"Thinking Out Loud\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                             \"Lakdi Ki Kathi\"[43]   \n",
       "23  24.                                      \"Faded\"[44]   \n",
       "24  25.                                    \"Perfect\"[45]   \n",
       "25  26.                                 \"Let Her Go\"[46]   \n",
       "26  27.                             \"Girls Like You\"[47]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[48]   \n",
       "28  29.                                    \"Lean On\"[49]   \n",
       "29  30.                                   \"Bailando\"[50]   \n",
       "\n",
       "                                         Uploader Views (in Billons)  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories              12.85   \n",
       "1                                      Luis Fonsi               8.16   \n",
       "2                                     LooLoo Kids               6.70   \n",
       "3                      Cocomelon – Nursery Rhymes               6.20   \n",
       "4                                      Ed Sheeran               6.00   \n",
       "5                                     Wiz Khalifa               5.89   \n",
       "6                                       ChuChu TV               5.30   \n",
       "7                      Cocomelon – Nursery Rhymes               5.24   \n",
       "8                                     Mark Ronson               4.92   \n",
       "9                                     Miroshka TV               4.89   \n",
       "10                                            Psy               4.80   \n",
       "11                                     Get Movies               4.55   \n",
       "12                                      El Chombo               4.35   \n",
       "13                                     Crazy Frog               3.91   \n",
       "14                                       Maroon 5               3.87   \n",
       "15                                     Katy Perry               3.80   \n",
       "16                                    OneRepublic               3.79   \n",
       "17                                  Justin Bieber               3.66   \n",
       "18                     Cocomelon – Nursery Rhymes               3.64   \n",
       "19                                     Ed Sheeran               3.60   \n",
       "20                                        Shakira               3.59   \n",
       "21                                     Katy Perry               3.52   \n",
       "22                                   Jingle Toons               3.48   \n",
       "23                                    Alan Walker               3.45   \n",
       "24                                     Ed Sheeran               3.45   \n",
       "25                                      Passenger               3.44   \n",
       "26                                       Maroon 5               3.42   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs               3.41   \n",
       "28                                    Major Lazer               3.38   \n",
       "29                               Enrique Iglesias               3.38   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6       March 6, 2014  \n",
       "7        May 24, 2018  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15  September 5, 2013  \n",
       "16       May 31, 2013  \n",
       "17   October 22, 2015  \n",
       "18      June 25, 2018  \n",
       "19    October 7, 2014  \n",
       "20       June 4, 2010  \n",
       "21  February 20, 2014  \n",
       "22      June 14, 2018  \n",
       "23   December 3, 2015  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26       May 31, 2018  \n",
       "27   January 26, 2018  \n",
       "28     March 22, 2015  \n",
       "29     April 11, 2014  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for scrap data\n",
    "Wiki_YT=pd.DataFrame({'Rank':Rank,'Video Name':Name,'Uploader':Artist,'Views (in Billons)':Views,'Upload Date':Upload_date})\n",
    "print('\\033[1m'+'Most Viewed Video on YouTube from Wikipedia :'+'\\033[0m')\n",
    "Wiki_YT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2511102",
   "metadata": {},
   "source": [
    "# 2. Scrape the details teamIndia’sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6125513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import re \n",
    "import time\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743660bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def India_fixtures():\n",
    "    \"\"\"Creating function that searches details of Team India International Fixtures\"\"\"\n",
    "\n",
    "    template = 'https://www.bcci.tv/.' #URL template for accessing the website\n",
    "    \n",
    "    driver = webdriver.Chrome() #Calling the Web Driver\n",
    "    driver.get(template) #Opening with the URL template\n",
    "    driver.maximize_window() #Maximize the Window\n",
    "    \n",
    "    time.sleep(5) #Making the Function wait for 5sec so webpage will open\n",
    "    \n",
    "    #Creating a variable \"Button\" to search the Fixtures and getting the 'href' to open in the driver.\n",
    "    button = driver.find_elements(By.XPATH,\"//div[@class = 'navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")\n",
    "    \n",
    "    button.get_attribute[\"href\"]\n",
    "    \n",
    "    time.sleep(5) #Making the Function wait for 5sec so webpage will open\n",
    "    \n",
    "    Match_title = [] #Creating Variable Match title to collect the title of the match i.e. Test or ODI.\n",
    "    Series = [] #Creating Variable Series to collect the Series name. \n",
    "    Place = [] #Creating variable Place to collect the Match venue.\n",
    "    Date = [] #Creating Variable Date to collect the venue Date.\n",
    "    Time = [] #Creating Variable Time to collect the venue Time.\n",
    "    details = [] #Creating a Dummy variable Details to collect the Date and time details\n",
    "    \n",
    "    #Scraping Match Details and appending in the Match list.\n",
    "    for i in driver.find_element(By.XPATH,\"//div [@class = 'fixture__format-strip']/ span [@class = 'u-unskewed-text fixture__format']\"):\n",
    "        Match_title.append(i.text)\n",
    "\n",
    "    #Scraping Series Details and appending in the Series list.    \n",
    "    for i in driver.find_elements(By.XPATH,\"//div [@class = 'fixture__format-strip']/ span [@class = 'u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "        Series.append(i.text)\n",
    "        \n",
    "   #Scraping Place Details and appending in the Place list.\n",
    "    for i in driver.find_element(By.XPATH,\"//div [@class = 'fixture__description u-unskewed-text']/p/span\"):\n",
    "        Place.append(i.text)\n",
    "    \n",
    "    #Scraping Date and Time Details and appending in the details list.\n",
    "    for i in driver.find_element(By.XPATH,\"//div [@class = 'fixture__datetime desktop-only']\"):\n",
    "        details.append(i.text.replace('\\n',' '))\n",
    "        \n",
    "    driver.close() #Exiting the driver post scraping the information    \n",
    "    \n",
    "    #Spliting the details list and sorting it in Date and Time. \n",
    "    Date = [i.split(' ',3)[:3]for i in details]\n",
    "    Date = [' '.join(i) for i in Date]\n",
    "    Time = [i.split(' ',3)[-1]for i in details]\n",
    "    \n",
    "    #Creating the DataFrame from all collected data\n",
    "    Fixtures = pd.DataFrame({'Match title' : Match_title , \n",
    "                             'Series' : Series , \n",
    "                             'Place' : Place, \n",
    "                             'Date' : Date ,\n",
    "                             'Time' : Time})\n",
    "    \n",
    "    return Fixtures #returns the DataFrame with collected details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f34f30f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get_attribute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mIndia_fixtures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mIndia_fixtures\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#Creating a variable \"Button\" to search the Fixtures and getting the 'href' to open in the driver.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m button \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//div[@class = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnavigation__drop-down drop-down drop-down--reveal-on-hover\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]/div/ul/li/a\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attribute\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     17\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;66;03m#Making the Function wait for 5sec so webpage will open\u001b[39;00m\n\u001b[0;32m     19\u001b[0m Match_title \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m#Creating Variable Match title to collect the title of the match i.e. Test or ODI.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_attribute'"
     ]
    }
   ],
   "source": [
    "India_fixtures()#Calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006594d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d93ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70abe36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e9ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a94ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723477d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171a2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40bf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00f5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b7d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1434fee7",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP at current price (19-20)\n",
    "\n",
    "D) GSDP at current price (18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77f6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import re \n",
    "import time\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cbfe2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def State_wise_GDP():\n",
    "    \"\"\"Creating function that searches details of India State_wise_GDP\"\"\"\n",
    "    \n",
    "    template = 'http://statisticstimes.com/'#URL template for accessing the website.\n",
    "    driver = webdriver.Chrome() #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details\n",
    "    for i in driver.find_elements(By.XPATH,\"//div [@class = 'dropdown']/div [@class = 'dropdown-content']/a\"):\n",
    "        href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[4]) #opening the href[4] which is GDP of India.\n",
    "    \n",
    "    href = [] #Declaring the list href to scrap all the href details of GDP of Indian states.\n",
    "    for i in driver.find_elements(By.XPATH,\"//div [@style = 'float:left;background-color:seashell;width:400px;height:800px;']/ul [@style = 'list-style-type:none;margin-left:20px;']/li/a\"):\n",
    "        if i.text == '» GDP of Indian states':\n",
    "            href.append(i.get_attribute('href'))\n",
    "    \n",
    "    driver.get(href[0]) #opening the href[4] which is GDP of Indian states.\n",
    "    \n",
    "    Rank = [] #Declaring Rank list to collect the Rank details\n",
    "    State = [] #Declaring State list to collect the State details\n",
    "    GSDP20 = [] #Declaring GSDP20 list to collect the GSDP20 details\n",
    "    GSDP19 = [] #Declaring GSDP19 list to collect the GSDP19 details\n",
    "    Share = [] #Declaring Share list to collect the Share details\n",
    "    GDP = [] #Declaring GDP list to collect the GDP details\n",
    "    details = [] #scraping all the above mentioned details and storing it in the details list.\n",
    "    for i in driver.find_elements(By.XPATH,\"//tbody /tr [@role = 'row']/td\"):\n",
    "        details.append(i.text)\n",
    "    \n",
    "    driver.close() #Exiting the Driver post collecting all the details.\n",
    "    \n",
    "    details = details[:264] #Sorting the list with the required details.\n",
    "    \n",
    "    z= 0\n",
    "    while z < len(details): # Splitting the collected details and storing it in the required list.\n",
    "        Rank.append(details[z])\n",
    "        z+=1\n",
    "        State.append(details[z])\n",
    "        z+=1\n",
    "        GSDP20.append(details[z])\n",
    "        z+=1\n",
    "        GSDP19.append(details[z])\n",
    "        z+=1\n",
    "        Share.append(details[z])\n",
    "        z+=1\n",
    "        GDP.append(details[z])\n",
    "        z+=3\n",
    "    \n",
    "    #Creating a DataFrame with collected details.\n",
    "    table = pd.DataFrame({\"Rank\" : Rank,\n",
    "                          \"State\" : State,\n",
    "                          \"GSDP(19-20)\" : GSDP20,\n",
    "                          \"GSDP(18-19)\" : GSDP19,\n",
    "                          \"Share(2018)\" : Share,\n",
    "                          \"GDP($ billion)\": GDP})\n",
    "    \n",
    "    return table #returing the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6448cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(2018)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank             State GSDP(19-20) GSDP(18-19) Share(2018) GDP($ billion)\n",
       "0     1       Maharashtra           -   2,632,792      13.94%        399.921\n",
       "1     2        Tamil Nadu   1,845,853   1,630,208       8.63%        247.629\n",
       "2     3     Uttar Pradesh   1,687,818   1,584,764       8.39%        240.726\n",
       "3     4           Gujarat           -   1,502,899       7.96%        228.290\n",
       "4     5         Karnataka   1,631,977   1,493,127       7.91%        226.806\n",
       "5     6       West Bengal   1,253,832   1,089,898       5.77%        165.556\n",
       "6     7         Rajasthan   1,020,989     942,586       4.99%        143.179\n",
       "7     8    Andhra Pradesh     972,782     862,957       4.57%        131.083\n",
       "8     9         Telangana     969,604     861,031       4.56%        130.791\n",
       "9    10    Madhya Pradesh     906,672     809,592       4.29%        122.977\n",
       "10   11            Kerala           -     781,653       4.14%        118.733\n",
       "11   12             Delhi     856,112     774,870       4.10%        117.703\n",
       "12   13           Haryana     831,610     734,163       3.89%        111.519\n",
       "13   14             Bihar     611,804     530,363       2.81%         80.562\n",
       "14   15            Punjab     574,760     526,376       2.79%         79.957\n",
       "15   16            Odisha     521,275     487,805       2.58%         74.098\n",
       "16   17             Assam           -     315,881       1.67%         47.982\n",
       "17   18      Chhattisgarh     329,180     304,063       1.61%         46.187\n",
       "18   19         Jharkhand     328,598     297,204       1.57%         45.145\n",
       "19   20       Uttarakhand           -     245,895       1.30%         37.351\n",
       "20   21   Jammu & Kashmir           -     155,956       0.83%         23.690\n",
       "21   22  Himachal Pradesh     165,472     153,845       0.81%         23.369\n",
       "22   23               Goa      80,449      73,170       0.39%         11.115\n",
       "23   24           Tripura      55,984      49,845       0.26%          7.571\n",
       "24   25        Chandigarh           -      42,114       0.22%          6.397\n",
       "25   26        Puducherry      38,253      34,433       0.18%          5.230\n",
       "26   27         Meghalaya      36,572      33,481       0.18%          5.086\n",
       "27   28            Sikkim      32,496      28,723       0.15%          4.363\n",
       "28   29           Manipur      31,790      27,870       0.15%          4.233\n",
       "29   30          Nagaland           -      27,283       0.14%          4.144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP = State_wise_GDP() #Calling the function and storing it in a variable.\n",
    "GDP.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41d18c",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a97fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import re \n",
    "import time\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a28d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\TRISHA ROY\\Downloads\\chromedriver_win32.exe\")\n",
    "time.sleep(1)\n",
    "\n",
    "# Opening Wikipedia webpage\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f5c0ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'click'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m trending\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//ul[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist-style-none mb-3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m][2]/li[3]/a\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrending\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ElementNotInteractableException:\n\u001b[0;32m      6\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(trending\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'click'"
     ]
    }
   ],
   "source": [
    "# Clicking on trending option\n",
    "trending=driver.find_elements(By.XPATH,'//ul[@class=\"list-style-none mb-3\"][2]/li[3]/a')\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7d285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db559f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82061ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c596d47",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79da87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_100():\n",
    "    \"\"\"Creating function that searches details of top 100 songs from billboard\"\"\"\n",
    "    \n",
    "    template = 'https://www.billboard.com/'#URL template for accessing the website.\n",
    "    driver = webdriver.Chrome()#Calling the Web Driver.\n",
    "    driver.get(template)#Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    \n",
    "    href = []#Creating href list to collect \"HOT 100\" href details.\n",
    "    for i in driver.find_elements(By.XPATH,\"//li [@class = 'header__subnav__item']/a\"):\n",
    "        if i.text == 'HOT 100':\n",
    "            href.append(i.get_attribute('href'))\n",
    "        \n",
    "    driver.get(href[0])# Opening the Driver with the collected href detail.\n",
    "    \n",
    "    #Scraping the Song_name and storing it in the Song_name list.\n",
    "    Song_name = [i.text for i in driver.find_elements(By.XPATH,\"// span [@class ='chart-element__information']/span[@ class= 'chart-element__information__song text--truncate color--primary']\")]\n",
    "    \n",
    "    #Scraping the Artist_name and storing it in the Artist_name list.\n",
    "    Artist_name = [i.text for i in driver.find_elements(By.XPATH,\"// span [@class ='chart-element__information']/span[@ class= 'chart-element__information__artist text--truncate color--secondary']\")]\n",
    "    \n",
    "    #Scraping the Last_week_rank and storing it in the Last_week_rank list.\n",
    "    Last_week_rank = [i.text for i in driver.find_elements(\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--last']\")]\n",
    "    \n",
    "    #Scraping the Peak_rank and storing it in the Peak_rank list.\n",
    "    Peak_rank = [i.text for i in driver.find_elements(By.XPATH,\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--peak']\")]\n",
    "    \n",
    "    #Scraping the Weeks_on_board and storing it in the Weeks_on_board list.\n",
    "    Weeks_on_board = [i.text for i in driver.find_elements(By.XPATH,\"//div[@class = 'chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class = 'chart-element__meta text--center color--secondary text--week']\")]\n",
    "    \n",
    "    driver.close()#Quiting the Driver post Scraping the Details Required.\n",
    " #Creating a DataFrame withe the collected Details.\n",
    "    table = pd.DataFrame({\"Song_name\" : Song_name,\n",
    "                          \"Artist_name\" : Artist_name,\n",
    "                          \"Last_week_rank\" : Last_week_rank,\n",
    "                          \"Peak_rank\" : Peak_rank,\n",
    "                          \"Weeks_on_board\": Weeks_on_board})\n",
    "    \n",
    "    return table #Retuting the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd351d76",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top_100songs \u001b[38;5;241m=\u001b[39m \u001b[43mtop_100\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Calling the Function and assigning it to a variable.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m top_100songs(\u001b[38;5;241m10\u001b[39m)\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mtop_100\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHOT 100\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m         href\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[43mhref\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;66;03m# Opening the Driver with the collected href detail.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#Scraping the Song_name and storing it in the Song_name list.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m Song_name \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m// span [@class =\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchart-element__information\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]/span[@ class= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchart-element__information__song text--truncate color--primary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "top_100songs = top_100() #Calling the Function and assigning it to a variable.\n",
    "top_100songs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee35e92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56237d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ad16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945549d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f11b49d3",
   "metadata": {},
   "source": [
    "# 9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd9ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\TRISHA ROY\\Downloads\\chromedriver_win32.exe\")\n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6417677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d7bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "find=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button')\n",
    "find.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533858f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]'):\n",
    "    link.append(i.get_attribute('href'))\n",
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0de799cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        recruiter=driver.find_element(By.XPATH,'//h1[@class=\"fl ellipsis wLimit hd\"]')\n",
    "        names.append(recruiter.text.replace('-',''))\n",
    "    except NoSuchElementException:\n",
    "        names.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dac9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=[]\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        D=driver.find_element(By.XPATH,'//div[@class=\"ellipsis\"]')\n",
    "        designation.append(D.text.replace('-',''))\n",
    "    except NoSuchElementException:\n",
    "        designation.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5884e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        C=driver.find_element(By.XPATH,'//a[@class=\"fl ellipsis widLrg\"]')\n",
    "        company.append(C.text.replace('-',''))\n",
    "    except NoSuchElementException:\n",
    "        company.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a193ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=[]\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        S=driver.find_element(By.XPATH,'//div[@class=\"fl lPortn\"]//p')\n",
    "        skills.append(S.text.replace('-',''))\n",
    "    except NoSuchElementException:\n",
    "        skills.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b304b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=[]\n",
    "for i in link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        L=driver.find_element(By.XPATH,'//h1[@class=\"f1 ellipsis loc\"]')\n",
    "        location.append(L.text.replace('-',''))\n",
    "    except NoSuchElementException:\n",
    "        location.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93f579d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(names),len(designation),len(company),len(skills),len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfb88e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>SKILLS</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>-</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>-</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>-</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>CoFounder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>-</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NAME        DESIGNATION COMPANY  \\\n",
       "0               Aakash Harit         HR Manager       -   \n",
       "1                          -                  -       -   \n",
       "2       shravan Kumar Gaddam  Company Recruiter       -   \n",
       "3                          -                  -       -   \n",
       "4   MARSIAN Technologies LLP         Company HR       -   \n",
       "..                       ...                ...     ...   \n",
       "95                         -                  -       -   \n",
       "96              Balaji Kolli          CoFounder       -   \n",
       "97                         -                  -       -   \n",
       "98            Rajani Nagaraj         HR Manager       -   \n",
       "99                         -                  -       -   \n",
       "\n",
       "                                               SKILLS LOCATION  \n",
       "0   Classic ASP Developer , Internet Marketing Pro...        -  \n",
       "1                                                   -        -  \n",
       "2   .Net , Java , Data Science , Linux Administrat...        -  \n",
       "3                                                   -        -  \n",
       "4                             Mid Level, Junior Level        -  \n",
       "..                                                ...      ...  \n",
       "95                                                  -        -  \n",
       "96                                                  -        -  \n",
       "97                                                  -        -  \n",
       "98  java , hadoop , r , Machine Learning , spark ,...        -  \n",
       "99                                                  -        -  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'NAME':names,'DESIGNATION':designation,'COMPANY':company,'SKILLS':skills,'LOCATION':location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8231d",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6494f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostwatched_tv_series():\n",
    "    \"\"\"The Function which searches and returns top selling novels from theguardian.com\"\"\"\n",
    "\n",
    "    template = 'https://www.imdb.com/list/ls095964455/' #URL template for accessing the website.\n",
    "    driver = webdriver.Chrome() #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    \n",
    "    #Creating the list Name and scraping the name of TV shows.\n",
    "    Name = [i.text for i in driver.find_elements(By.XPATH,\"//h3 [@class ='lister-item-header']/a\")]\n",
    "    \n",
    "    #Creating the list Year_span and scraping the Year_span of TV shows.\n",
    "    Year_span = [i.text for i in driver.find_elements(By.XPATH,\"//h3 [@class ='lister-item-header']/span[@class = 'lister-item-year text-muted unbold']\")]\n",
    "    \n",
    "    #Creating the list Genre and scraping the Genre of TV shows.\n",
    "    Genre = [i.text for i in driver.find_elements(By.XPATH,\"//p [@class ='text-muted text-small']/span[@class = 'genre']\")]\n",
    "    \n",
    "    #Creating the list Run_time and scraping the Run_time of TV shows.\n",
    "    Run_time = [i.text for i in driver.find_elements(By.XPATH,\"//p [@class ='text-muted text-small']/span[@class = 'runtime']\")]\n",
    "    \n",
    "    #Creating the list Ratings and scraping the Ratings of TV shows.\n",
    "    Ratings = [i.text for i in driver.find_elements(By.XPATH,\"//div [@class ='ipl-rating-star small']/span[@class = 'ipl-rating-star__rating']\")]\n",
    "    \n",
    "    #Creating the list Votes and scraping the Votes of TV shows.\n",
    "    Votes = [i.text for i in driver.find_elements(By.XPATH,\"//p [@class ='text-muted text-small']/span[@name = 'nv']\")]\n",
    "    \n",
    "    driver.quit()#exiting the driver post scraping the information\n",
    "    \n",
    "    #Creating a Dataframe with all collected details.\n",
    "    table = pd.DataFrame({\"Name\" : Name,\n",
    "                          \"Year_span\" : Year_span,\n",
    "                          \"Genre\" : Genre,\n",
    "                          \"Run_time\" : Run_time,\n",
    "                          \"Ratings\": Ratings,\n",
    "                          \"Votes\" : Votes})\n",
    "    \n",
    "    return table #Returning the DataFrame.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009fc92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,163,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,243,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,027,704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>302,304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>261,418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>207,730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>258,372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  2,163,377  \n",
       "1    51 min     8.7  1,243,199  \n",
       "2    44 min     8.1  1,027,704  \n",
       "3    60 min     7.5    302,304  \n",
       "4    43 min     7.6    261,418  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,692  \n",
       "96   50 min     7.8     63,735  \n",
       "97   42 min     8.1    207,730  \n",
       "98   45 min       7     43,226  \n",
       "99  572 min     8.6    258,372  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostwatched_tv_series() #calling the Function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a768b",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b8810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Highest_selling_novels():\n",
    "    \"\"\"The Function which searches and returns top selling novels from theguardian.com\"\"\"\n",
    "    \n",
    "    #URL template for accessing the website.\n",
    "    template = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "    driver = webdriver.Chrome()#Calling the Web Driver.\n",
    "    driver.get(template)#Opening with the URL template.\n",
    "    driver.maximize_window()#Maximize the Window.\n",
    "    \n",
    "    #Creating a dummy list and scraping the all the required details.\n",
    "    dummy = [i.text for i in driver.find_elements(By.XPATH,\"//table [@class ='in-article sortable']//tr/td\")]\n",
    "    \n",
    "    driver.close() #Quiting the driver post collecting the details. \n",
    "    \n",
    "    dummy.remove('SOURCE: NIELSEN BOOK SCAN') #Removing the unwanted details from dummy list. \n",
    "\n",
    "    Book_name = [] #Creating list Book_name to collect the Book_name details.\n",
    "    Author_name = [] #Creating list Author_name to collect the Author_name details.\n",
    "    Volumes_sold = [] #Creating list Volumes_sold to collect the Volumes_sold details.\n",
    "    Publisher = [] #Creating list Publisher to collect the Publisher details.\n",
    "    Genre = [] #Creating list Genre to collect the Genre details.\n",
    "\n",
    "    z = 0\n",
    "    while z < len(dummy): #Splitting dummy list and storing the required details it in the appropriate list.\n",
    "        z+=1\n",
    "        Book_name.append(dummy[z])\n",
    "        z+=1\n",
    "        Author_name.append(dummy[z])\n",
    "        z+=1\n",
    "        Volumes_sold.append(dummy[z])\n",
    "        z+=1\n",
    "        Publisher.append(dummy[z])\n",
    "        z+=1\n",
    "        Genre.append(dummy[z])\n",
    "        z+=1\n",
    "     #Creating the DataFrame with all the collected details.\n",
    "    table = pd.DataFrame({\"Book_name\" : Book_name,\n",
    "                          \"Author_name\" : Author_name,\n",
    "                          \"Volumes_sold\" : Volumes_sold,\n",
    "                          \"Publisher\" : Publisher,\n",
    "                          \"Genre\": Genre})\n",
    "    \n",
    "    return table #returning the DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e351a33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_selling_novels()#calling the Function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273900bc",
   "metadata": {},
   "source": [
    "# 8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc84b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UCI_Repository():\n",
    "    \"\"\"The Function that Search all the ML Repository details and return them in DataFrame\"\"\"\n",
    "\n",
    "    template = 'https://archive.ics.uci.edu/' #URL template for accessing the website.\n",
    "    driver = webdriver.Chrome() #Calling the Web Driver.\n",
    "    driver.get(template) #Opening with the URL template.\n",
    "    driver.maximize_window() #Maximize the Window.\n",
    "    time.sleep(3)#making the function to wait for 3sec\n",
    "    \n",
    "    #finding view all repository and clicking the same.\n",
    "    ml_repository = driver.find_element(By.XPATH,\"//span [@class ='normal']/b/a\")\n",
    "    ml_repository.click()\n",
    "    \n",
    "    #creating a dummy list 'details' and scraping Dataset_name, Data_type, Task, Attribute_type, Noof_instances, Noof_attribute, Year.\n",
    "    details = [i.text for i in driver.find_elements(By.XPATH,\"//table [@border ='1']/tbody/tr/td\")]\n",
    "    del details[:7] #Removing the unwanted details.\n",
    "    \n",
    "    driver.close() #Closing the Driver post scraping the details.\n",
    "    \n",
    "    Dataset_name = [] #creating list Dataset_name to collect Dataset_name. \n",
    "    Data_type = [] #creating list Data_type to collect Data_type. \n",
    "    Task = [] #creating list Task to collect Task. \n",
    "    Attribute_type = [] #creating list Attribute_type to collect Attribute_type. \n",
    "    Noof_instances = [] #creating list Noof_instances to collect Noof_instances. \n",
    "    Noof_attribute = [] #creating list Noof_attribute to collect Noof_attribute. \n",
    "    Year = [] #creating list Year to collect Year. \n",
    "\n",
    "    z= 0\n",
    "    while z < len(details): #Splitting the Dummy variable and storing it in a appropriate list.\n",
    "        Dataset_name.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Data_type.append(details[z])\n",
    "        z +=1\n",
    "    \n",
    "        Task.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Attribute_type.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Noof_instances.append(details[z])\n",
    "        z +=1\n",
    "    \n",
    "        Noof_attribute.append(details[z])\n",
    "        z +=1\n",
    "\n",
    "        Year.append(details[z])\n",
    "        z +=1\n",
    "        \n",
    "        \n",
    "    #Creating DataFrame with collected Details    \n",
    "    table = pd.DataFrame({\"Dataset_name\" : Dataset_name,\n",
    "                          \"Data_type\" : Data_type,\n",
    "                          \"Task\" : Task,\n",
    "                          \"Attribute_type\" : Attribute_type,\n",
    "                          \"Noof_instances\" : Noof_instances,\n",
    "                          \"Noof_attribute\" : Noof_attribute,\n",
    "                          \"Year\" : Year})\n",
    "        \n",
    "    table = table.replace(' ', '-')\n",
    "        \n",
    "    return table #returning the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61a57893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>Noof_instances</th>\n",
       "      <th>Noof_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial Characters</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>6000</td>\n",
       "      <td>7</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Audiology (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>-</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Audiology (Standardized)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>69</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>398</td>\n",
       "      <td>8</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>205</td>\n",
       "      <td>26</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Badges</td>\n",
       "      <td>Univariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balance Scale</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>625</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Balloons</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>286</td>\n",
       "      <td>9</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>699</td>\n",
       "      <td>10</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Breast Cancer Wisconsin (Prognostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>198</td>\n",
       "      <td>34</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>32</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pittsburgh Bridges</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>108</td>\n",
       "      <td>13</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Dataset_name          Data_type  \\\n",
       "0                                  Abalone      Multivariate    \n",
       "1                                    Adult      Multivariate    \n",
       "2                                Annealing      Multivariate    \n",
       "3             Anonymous Microsoft Web Data                  -   \n",
       "4                               Arrhythmia      Multivariate    \n",
       "5                    Artificial Characters      Multivariate    \n",
       "6                     Audiology (Original)      Multivariate    \n",
       "7                 Audiology (Standardized)      Multivariate    \n",
       "8                                 Auto MPG      Multivariate    \n",
       "9                               Automobile      Multivariate    \n",
       "10                                  Badges  Univariate, Text    \n",
       "11                           Balance Scale      Multivariate    \n",
       "12                                Balloons      Multivariate    \n",
       "13                           Breast Cancer      Multivariate    \n",
       "14      Breast Cancer Wisconsin (Original)      Multivariate    \n",
       "15    Breast Cancer Wisconsin (Prognostic)      Multivariate    \n",
       "16    Breast Cancer Wisconsin (Diagnostic)      Multivariate    \n",
       "17                      Pittsburgh Bridges      Multivariate    \n",
       "18                          Car Evaluation      Multivariate    \n",
       "19                           Census Income      Multivariate    \n",
       "\n",
       "                           Task               Attribute_type Noof_instances  \\\n",
       "0               Classification   Categorical, Integer, Real           4177    \n",
       "1               Classification         Categorical, Integer          48842    \n",
       "2               Classification   Categorical, Integer, Real            798    \n",
       "3          Recommender-Systems                  Categorical          37711    \n",
       "4               Classification   Categorical, Integer, Real            452    \n",
       "5               Classification   Categorical, Integer, Real           6000    \n",
       "6               Classification                  Categorical            226    \n",
       "7               Classification                  Categorical            226    \n",
       "8                   Regression            Categorical, Real            398    \n",
       "9                   Regression   Categorical, Integer, Real            205    \n",
       "10              Classification                             -           294    \n",
       "11              Classification                  Categorical            625    \n",
       "12              Classification                  Categorical             16    \n",
       "13              Classification                  Categorical            286    \n",
       "14              Classification                      Integer            699    \n",
       "15  Classification, Regression                         Real            198    \n",
       "16              Classification                         Real            569    \n",
       "17              Classification         Categorical, Integer            108    \n",
       "18              Classification                  Categorical           1728    \n",
       "19              Classification         Categorical, Integer          48842    \n",
       "\n",
       "   Noof_attribute   Year  \n",
       "0              8   1995   \n",
       "1             14   1996   \n",
       "2             38       -  \n",
       "3            294   1998   \n",
       "4            279   1998   \n",
       "5              7   1992   \n",
       "6               -  1987   \n",
       "7             69   1992   \n",
       "8              8   1993   \n",
       "9             26   1987   \n",
       "10             1   1994   \n",
       "11             4   1994   \n",
       "12             4       -  \n",
       "13             9   1988   \n",
       "14            10   1992   \n",
       "15            34   1995   \n",
       "16            32   1995   \n",
       "17            13   1990   \n",
       "18             6   1997   \n",
       "19            14   1996   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI_Repository = UCI_Repository() #Calling the function and storing it in a variable.\n",
    "UCI_Repository.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9973fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
